# modules/chatbot_engine.py

import os
from dotenv import load_dotenv

# Charger les variables d'environnement
load_dotenv()

# D√©sactiver la t√©l√©m√©trie ChromaDB
os.environ["ANONYMIZED_TELEMETRY"] = "False"

from huggingface_hub import InferenceClient
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
import logging

# ------------------ Configuration ------------------ #
CHROMA_PATH = "chroma"
EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"
HF_API_KEY = os.getenv("HF_API_KEY")

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Template simplifi√©
prompt_template = """Tu es un expert en cybers√©curit√©. R√©ponds de mani√®re claire et technique.

Contexte:
{context}

Question: {question}

R√©ponse:"""

# ------------------ Client Hugging Face ------------------ #
client = None


def initialize_client():
    """Initialise le client avec la nouvelle API"""
    global client

    if not HF_API_KEY:
        logger.error("‚ùå HF_API_KEY non d√©finie")
        return False

    try:
        # Initialiser le client
        client = InferenceClient(token=HF_API_KEY)

        # Test avec chat_completion (au lieu de text_generation)
        logger.info("üîÑ Test de connexion avec Qwen...")
        test_messages = [{"role": "user", "content": "Hello"}]
        test_response = client.chat_completion(
            messages=test_messages,
            model="Qwen/Qwen2.5-72B-Instruct",
            max_tokens=5
        )

        logger.info("‚úÖ Client initialis√© avec succ√®s")
        return True

    except Exception as e:
        logger.error(f"‚ùå Erreur d'initialisation : {str(e)}")
        client = None
        return False


# ------------------ Fonction principale ------------------ #
def answer_question(query_text, k=3):
    """
    R√©pond √† une question en utilisant RAG + LLM

    Args:
        query_text (str): La question de l'utilisateur
        k (int): Nombre de documents √† r√©cup√©rer

    Returns:
        tuple: (r√©ponse, sources)
    """

    if not client:
        logger.error("Client non initialis√©")
        if not initialize_client():
            return "‚ùå Impossible de se connecter √† l'API Hugging Face.", []

    try:
        # 1Ô∏è‚É£ Recherche dans ChromaDB
        logger.info("üîç Recherche dans la base de connaissances...")
        embedding_function = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)

        db = Chroma(
            persist_directory=CHROMA_PATH,
            embedding_function=embedding_function
        )

        # 2Ô∏è‚É£ R√©cup√©ration des documents
        results = db.similarity_search_with_relevance_scores(query_text, k=k)

        if not results:
            logger.warning("‚ö†Ô∏è Aucun document trouv√©")
            return "Aucun document pertinent trouv√©.", []

        logger.info(f"üìö {len(results)} documents trouv√©s")

        # 3Ô∏è‚É£ Construction du prompt
        context_text = "\n---\n".join([doc.page_content for doc, _ in results])
        prompt = prompt_template.format(context=context_text, question=query_text)

        # 4Ô∏è‚É£ G√©n√©ration avec chat_completion (format conversationnel)
        logger.info("ü§ñ G√©n√©ration de la r√©ponse...")

        # Liste de mod√®les gratuits disponibles
        models_to_try = [
            "Qwen/Qwen2.5-72B-Instruct",
            "meta-llama/Llama-3.2-3B-Instruct",
            "mistralai/Mistral-7B-Instruct-v0.3",
            "microsoft/Phi-3.5-mini-instruct"
        ]

        response_text = None
        for model_name in models_to_try:
            try:
                logger.info(f"   Essai avec {model_name}...")

                # Format de messages pour chat
                messages = [
                    {"role": "system",
                     "content": "Tu es un expert en cybers√©curit√©. R√©ponds de mani√®re claire et technique."},
                    {"role": "user", "content": f"Contexte:\n{context_text}\n\nQuestion: {query_text}"}
                ]

                response = client.chat_completion(
                    messages=messages,
                    model=model_name,
                    max_tokens=300,
                    temperature=0.3
                )

                # Extraire le contenu de la r√©ponse
                response_text = response.choices[0].message.content
                logger.info(f"   ‚úÖ R√©ponse obtenue avec {model_name}")
                break

            except Exception as e:
                logger.warning(f"   ‚ö†Ô∏è {model_name} non disponible: {str(e)[:80]}")
                continue

        if not response_text:
            return "‚ùå Aucun mod√®le disponible actuellement. R√©essaye dans quelques minutes.", []

        # 5Ô∏è‚É£ Nettoyage
        response_text = response_text.strip()

        # 6Ô∏è‚É£ Sources
        sources = []
        for doc, score in results:
            source = doc.metadata.get("source", "Inconnu")
            sources.append(f"{source} (score: {score:.2f})")

        logger.info("‚úÖ R√©ponse g√©n√©r√©e")

        del db
        return response_text, sources

    except Exception as e:
        logger.error(f"‚ùå Erreur : {str(e)}")
        return f"‚ùå Erreur : {str(e)}", []


# ------------------ Initialisation ------------------ #
logger.info("üöÄ D√©marrage du chatbot...")
initialize_client()

# ------------------ Test ------------------ #
if __name__ == "__main__":
    print("\n" + "=" * 70)
    print("ü§ñ CHATBOT RAG CYBERS√âCURIT√â - MOD√àLES GRATUITS")
    print("=" * 70)

    if not HF_API_KEY:
        print("\n‚ùå HF_API_KEY non d√©finie !")
        print("\nüìù Cr√©e un fichier .env avec:")
        print("   HF_API_KEY=hf_ton_token_ici")
        print("\nOu r√©cup√®re un token sur: https://huggingface.co/settings/tokens")
        print("=" * 70)
        exit(1)

    if not client:
        print("\n‚ùå Client non initialis√©.")
        print("V√©rifie ta connexion internet et ta cl√© API.\n")
        exit(1)

    question = "Quels sont les principaux risques d'une injection SQL ?"

    print(f"\nüîç Question : {question}")
    print("‚è≥ G√©n√©ration en cours...\n")

    answer, sources = answer_question(question)

    print("‚úÖ R√âPONSE :")
    print("-" * 70)
    print(answer)
    print("-" * 70)

    if sources:
        print("\nüìö SOURCES :")
        for i, source in enumerate(sources, 1):
            print(f"   {i}. {source}")

    print("\n" + "=" * 70)
    print("‚ú® Termin√© !")
    print("=" * 70 + "\n")